<html>
    <head>
        <title>Time Complexity</title>
        <link rel="stylesheet" href="./index.css" type="text/css"/>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
    </head>
    <body>
        <div class="content">
            <h1>Time Complexity</h1>
            <p>
            Time complexity is a measure of the runtime of an algorithm.
            The complexity of a function \(f(n)\) is represented using big \(\mathcal{O}\) notation.
            <br><br>
            Here are some common complexities:
            <br><br>
            <ul>
                <li>
                    \(\mathcal{O}(1)\) - Also known as constant time, algorithms with this 
                    complexity use a constant number of operations (eg. addition).
                </li>
                <br>
                <li>
                    \(\mathcal{O}(\log N)\) - Algorithms with this complexity use a logarithmic 
                    number of operations (eg. binary search).
                </li>
                <br>
                <li>
                    \(\mathcal{O}(N)\) - Linear time complexity, linear number of operations (eg. linear search).
                </li>
                <br>
                <li>
                    \(\mathcal{O}(N \log N)\) - Linearithmic time complexity (eg. <b>average complexity</b> of merge sort)
                </li>
                <br>
                <li>
                    \(\mathcal{O}(N^2)\) - A quadratic time complexity (eg. iterating through all substrings of a string)
                </li>
                <br>
                <li>
                    \(\mathcal{O}(N!)\) - This is factorial complexity (eg. iterating through all permutations)
                </li>
            </ul>
            <br>
            With time complexity, we can estimate the number of operations our program will use, and thus, 
            estimate the time it will take for it to run. 
            <br>
            For example, an \(\mathcal{O}(N)\)
            will use \(100\text{ }000\) operations for an input of size \(100\text{ }000\).
            <br><br>
            With an \(\mathcal{O}(N^2)\) algorithm, about \(10^\text{10}\) operations will be used for an input of the same size. 
            <br><br>
            With an \(\mathcal{O}(\log_2 N)\) algorithm, only around \(17\) operations will be used for an input of the same size (not including reading input). 
            <br><br>
            Note that "operations" may mean different things and is not the best indicator of how long a program will take.
            This variation is known as a <b>constant factor</b>.
            <br> 
            However, it will often give us a good enough estimate for solving problems.
            <br><br>
            On most judges, a time limit of \(1\) second can allow up to \(10^8\) operations with a decent constant factor.
            <br>
            Constant factors are often removed from complexity notations.
            <br>
            There are many ways to optimize code to improve constant factors, but they will not be discussed within this section.
            <br><br>
            <h2>Different notations of complexity</h2>
            There are different types of complexity, notably:
            <br><br>
            <ul>
                <li>Average complexity, as stated earlier</li><br>
                <li>Amortized complexity</li><br>
                <li>Worst-case complexity</li><br>
                <li>Expected complexity</li>
            </ul>
            <br>
            For more information, see the following <a href="https://people.ksp.sk/~kuko/gnarley-trees/Complexity2.html">link</a>.
            <br><br>    
            <h2>Examples</h2>
            The following problem will be used to showcase how algorithms of different complexities solve the same problem.
            <br><br>
            <code>
                Given an array of </code> \(N\text{ }\) <code> integers, return the largest element of this array.
            </code>
            <h4>\(\mathcal{O}(N^2)\) solution:</h4>
            For each element, iterate the entire list to check if there is a number greater than it. If this is not the case, 
            then we have found it-<br>
            otherwise, go to the next element.
            <br><br>
            This algorithm has a worst-case time complexity of \(\mathcal{O}(N^2)\) as there is a possibility to iterate all \(N\) elements \(N\) times. 
            <br>
            The implementation is shown here (C++):
            <br><br>
            <code><pre>
int f(int *arr, int n) { // n is the length of the array
    for (int const &elem: arr) {
        bool hasGreater = false;
        for (int const &cmp: arr) {
            if (cmp > elem) hasGreater = true;
        }
        if (!hasGreater) return elem;
    }
    return -1;
}
            </pre></code>
            <br>
            A simple way to find the time complexity of a program is to observe 
            loops in the code (i.e. for loops, while loops). 
            <br>
            In this case, we see that there are two nested loops, both of which iterate 
            the entire array. Knowing that an iteration is \(N\) operations,
            <br>
            and the program performs this iteration \(N\) times, \(N \times N\) = \(N^2\).
            <br><br>
            Note that built-in methods or functions are not all \(\mathcal{O}(1)\) operations - this is a common 
            <br>mistake when identifying the complexity of a program.
            <h4>\(\mathcal{O}(N \log N)\) solution:</h4>
            There are many different types of sorting algorithms, with different complexities.
            <br>
            Simple, yet less efficient sorting algorithms, such as bubble sort, run in \(\mathcal{O}(N^2)\) time 
            on average.
            <br>
            Efficient sorting algorithms have an average runtime of \(\mathcal{O}(N \log N)\) which is 
            what is generally accepted as the time complexity of of sorting.
            <br><br>
            In C++, the <code>std::sort()</code> function has an average runtime of \(\mathcal{O}(N \log N)\),
            <br> 
            but in Java the <code>Arrays.sort()</code> method is slow - the worst case runtime is \(\mathcal{O}(N^2)\).
            <br><br>
            The many sorting algorithms will not be explained here, but for further information, see the following 
            <a href="https://en.wikipedia.org/wiki/Sorting_algorithm">link</a>.
            <br><br>
            <code><pre>
int f(int *arr, int n) { // n is the length of the array
    std::sort(arr, arr + n);
    return arr[n-1];
}
            </pre></code>
            <h4>\(\mathcal{O}(N)\) solution:</h4>
            This is the most efficient algorithm for this problem.
            <br><br>
            We can maintain a variable that stores the maximum element for the first \(i\) elements,
            and update it should the <br>
            next one be greater than the current maximum. This only requires one iteration of the array, 
            <br>thus the algorithm's time complexity is \(\mathcal{O}(N)\).
            <br><br>
            <code><pre>
int f(int *arr, int n) { // n is the length of the array
    int mx = INT_MIN;
    for (int const &elem: arr) {
        if (elem > mx) mx = elem;
    }
    return mx;
}
            </pre></code>
            <br>
            Remember that array accessing, comparisons, and assignments are constant time operations.
            <br><br>
            <h2>Final thoughts</h2>
            Here are estimates of the input size various time complexities can run in one second:
            <ul>
                <li>\(N \le 10\): \(\mathcal{O}(N!)\)</li><br>  
                <li>\(N \le 5\text{ }000\): \(\mathcal{O}(N^2)\)</li><br>
                <li>\(N \le 500\text{ }000\): \(\mathcal{O}(N \log N)\)</li><br>
                <li>\(N \le 10^7\): \(\mathcal{O}(N)\)</li><br>
                <li>\(N \le 10^\text{18}\): \(\mathcal{O}(\log N)\), \(\mathcal{O}(1)\)</li><br>
            </ul>
            <br>
            Once again, constant factors may influence this, and is not a perfectly accurate measurement.
            <br><br>
            <h2>Resources & references</h2>
            <ul>
                <li>
                    <a href="https://usaco.guide/bronze/time-comp?lang=cpp">USACO guide</a>
                </ll>
            </ul>
            </p>
            <br><br><br>
        </div>
    </body>
</html>
